{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whr9pySjG8yd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! pip install pandas\n",
        "! pip install pytube\n",
        "! pip install numpy\n",
        "! pip install pinecone-client\n",
        "! pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfXF3-S-IU_L"
      },
      "outputs": [],
      "source": [
        "# Import the modules\n",
        "import os\n",
        "import torch\n",
        "import whisper\n",
        "import pinecone\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRJaOc6-IaOV"
      },
      "outputs": [],
      "source": [
        "def video_to_audio(video_url, destination):\n",
        "\n",
        "    # Get the video\n",
        "    video = YouTube(video_url)\n",
        "\n",
        "    # Convert video to Audio\n",
        "    audio = video.streams.filter(only_audio=True).first()\n",
        "\n",
        "    # Save to destination\n",
        "    output = audio.download(output_path = destination)\n",
        "\n",
        "    name, ext = os.path.splitext(output)\n",
        "    new_file = name + '.mp3'\n",
        "\n",
        "    # Replace spaces with \"_\"\n",
        "    new_file = new_file.replace(\" \", \"_\")\n",
        "\n",
        "    # Change the name of the file\n",
        "    os.rename(output, new_file)\n",
        "\n",
        "    return new_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n13nfbQIfZq"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir \"audio_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-hoBEi8InCL"
      },
      "outputs": [],
      "source": [
        "# Create URL column\n",
        "audio_path = \"audio_data\"\n",
        "\n",
        "# Have just provided a sample of links for experimentation purpose\n",
        "list_videos = [\"https://www.youtube.com/watch?v=IdTMDpizis8\",\n",
        "              \"https://www.youtube.com/watch?v=fLeJJPxua3E\",\n",
        "              \"https://www.youtube.com/watch?v=z3FA2kALScU\"]\n",
        "# Create dataframe\n",
        "transcription_df = pd.DataFrame(list_videos, columns=['URLs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeuLSMbkIoND"
      },
      "outputs": [],
      "source": [
        "\n",
        "transcription_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbGxPPwfIrFQ"
      },
      "outputs": [],
      "source": [
        "# Create the files_name\n",
        "transcription_df[\"file_name\"] = transcription_df[\"URLs\"].apply(lambda url: video_to_audio(url, audio_path))\n",
        "transcription_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuFeg71oIt4e"
      },
      "outputs": [],
      "source": [
        "# Set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model\n",
        "whisper_model = whisper.load_model(\"base\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "490_i7XAOIf6"
      },
      "outputs": [],
      "source": [
        "def audio_to_text(audio_file):\n",
        "\n",
        "    return whisper_model.transcribe(audio_file)[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DelG9fXBOLLf"
      },
      "outputs": [],
      "source": [
        "# Apply the function to all the audio files\n",
        "transcription_df[\"transcriptions\"] = transcription_df[\"file_name\"].apply(lambda f_name: audio_to_text(f_name))\n",
        "\n",
        "\n",
        "# Show the first five rows\n",
        "transcription_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ0ixNobOUTS"
      },
      "outputs": [],
      "source": [
        "transcription_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"sentence-transformers/all-MiniLM-L6-v2\""
      ],
      "metadata": {
        "id": "DSfRz_vU0c3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "os.environ[\"HUGGING_FACE_TOKEN\"] = getpass('Enter Hugging Face token: ')\n",
        "hf_token = os.getenv('HUGGING_FACE_TOKEN')"
      ],
      "metadata": {
        "id": "DrhHaFbzfl2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
        "headers = {\"Authorization\": f\"Bearer {hf_token}\"}"
      ],
      "metadata": {
        "id": "BH9hR2JV0pKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(texts):\n",
        "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "sC9otQxe0u_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription_df[\"embedding\"] = transcription_df[\"transcriptions\"].astype(str).apply(query)"
      ],
      "metadata": {
        "id": "bM-kZru01LuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXxw58woOggL"
      },
      "outputs": [],
      "source": [
        "transcription_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZQveIHvOi2d"
      },
      "outputs": [],
      "source": [
        "vector_dim = transcription_df.iloc[2].embedding\n",
        "len(vector_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = getpass('Enter your Pinecone API Key: ')"
      ],
      "metadata": {
        "id": "qKfNJ0AB3DKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PINECONE_ENVIRONMENT\"] = getpass('Enter your Pinecone Environment: ')"
      ],
      "metadata": {
        "id": "1-v9xbae3Hpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find API key in console at app.pinecone.io\n",
        "api_key = os.getenv('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
        "# find ENV (cloud region) next to API key in console\n",
        "env = os.getenv('PINECONE_ENVIRONMENT') or 'PINECONE_ENVIRONMENT'\n",
        "\n",
        "# Initialize connection to pinecone\n",
        "pinecone.init(\n",
        "  api_key=api_key,\n",
        "  environment=env\n",
        ")"
      ],
      "metadata": {
        "id": "8iseMCvslEgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJFDt2ayOlKa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Index params\n",
        "my_index_name = \"audio-search\"\n",
        "vector_dim = len(transcription_df.iloc[0].embedding)\n",
        "\n",
        "if my_index_name not in pinecone.list_indexes():\n",
        "  # Create the index\n",
        "  pinecone.create_index(name = my_index_name,\n",
        "                      dimension=vector_dim,\n",
        "                      metric=\"cosine\", shards=1,\n",
        "                      pod_type='s1.x1')\n",
        "# Connect to the index\n",
        "my_index = pinecone.Index(index_name = my_index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytD9KY83OrEI"
      },
      "outputs": [],
      "source": [
        "transcription_df[\"vector_id\"] = transcription_df.index\n",
        "transcription_df[\"vector_id\"] = transcription_df[\"vector_id\"].apply(str)\n",
        "\n",
        "# Get all the metadata\n",
        "final_metadata = []\n",
        "\n",
        "for index in range(len(transcription_df)):\n",
        "  final_metadata.append({\n",
        "      'ID':  index,\n",
        "      'url': transcription_df.iloc[index].URLs,\n",
        "      'transcription': transcription_df.iloc[index].transcriptions\n",
        "  })\n",
        "\n",
        "audio_IDs = transcription_df.vector_id.tolist()\n",
        "audio_embeddings = [arr for arr in transcription_df.embedding]\n",
        "\n",
        "# Create the single list of dictionary format to insert\n",
        "data_to_upsert = list(zip(audio_IDs, audio_embeddings, final_metadata))\n",
        "\n",
        "# Upload the final data\n",
        "my_index.upsert(vectors = data_to_upsert)\n",
        "\n",
        "# Show information about the vector index\n",
        "my_index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTAJpC5JOte6"
      },
      "outputs": [],
      "source": [
        "N = 2\n",
        "my_query_embedding = transcription_df.embedding[0]\n",
        "\n",
        "# Run the Query Search\n",
        "my_index.query(my_query_embedding, top_k=N, include_metadata=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}