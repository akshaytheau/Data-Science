{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Gensim stands for \"Generate Similar\"\n",
    "\n",
    "2)Features provided by <b>Gensim</b> :\n",
    "\n",
    "a)fastText<br>\n",
    "b)word2vec<br> \n",
    "c)LSA<br>\n",
    "d)LDA<br>\n",
    "e)TF-IDF<br>\n",
    "\n",
    "<b>Documents : </b> It refers to some text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Akshay is teaching gensim on youtube.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Corpus : </b> It refers to collection of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Akshay is teaching gensim on youtube.\",\"Today is a sunny day\",\"India is one of the top ranking teasm in cricket\",\"My favourite hobby is playing badminton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "processed_corpus = [[word for word in document.lower().split() if word not in stoplist]\n",
    "   for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['akshay', 'is', 'teaching', 'gensim', 'on', 'youtube.'],\n",
      " ['today', 'is', 'sunny', 'day'],\n",
      " ['india', 'is', 'one', 'top', 'ranking', 'teasm', 'cricket'],\n",
      " ['my', 'favourite', 'hobby', 'is', 'playing', 'badminton']]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"'Akshay is teaching gensim on youtube.',\"Today is a sunny day\",\"India is one of the top ranking teasm in cricket\",'My favourite hobby is playing badminton'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akshay',\n",
       " 'is',\n",
       " 'teaching',\n",
       " 'gensim',\n",
       " 'on',\n",
       " 'youtube',\n",
       " 'today',\n",
       " 'is',\n",
       " 'sunny',\n",
       " 'day',\n",
       " 'india',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'top',\n",
       " 'ranking',\n",
       " 'teasm',\n",
       " 'in',\n",
       " 'cricket',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'hobby',\n",
       " 'is',\n",
       " 'playing',\n",
       " 'badminton']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(corpus, deacc=False, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document is text and vector is a mathematically convenient representation of that text.\n",
    "\n",
    "One more important thing to be noted here is that, two different documents may have the same vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(20 unique tokens: ['akshay', 'gensim', 'is', 'on', 'teaching']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'akshay': 0,\n",
      " 'badminton': 15,\n",
      " 'cricket': 9,\n",
      " 'day': 6,\n",
      " 'favourite': 16,\n",
      " 'gensim': 1,\n",
      " 'hobby': 17,\n",
      " 'india': 10,\n",
      " 'is': 2,\n",
      " 'my': 18,\n",
      " 'on': 3,\n",
      " 'one': 11,\n",
      " 'playing': 19,\n",
      " 'ranking': 12,\n",
      " 'sunny': 7,\n",
      " 'teaching': 4,\n",
      " 'teasm': 13,\n",
      " 'today': 8,\n",
      " 'top': 14,\n",
      " 'youtube.': 5}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['akshay', 'is', 'teaching', 'gensim', 'on', 'youtube.'],\n",
       " ['today', 'is', 'sunny', 'day'],\n",
       " ['india', 'is', 'one', 'top', 'ranking', 'teasm', 'cricket'],\n",
       " ['my', 'favourite', 'hobby', 'is', 'playing', 'badminton']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
      " [(2, 1), (6, 1), (7, 1), (8, 1)],\n",
      " [(2, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
      " [(2, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]]\n"
     ]
    }
   ],
   "source": [
    "BoW_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(BoW_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=4, num_nnz=23)\n",
      "[(0, 0.7071067811865475), (9, 0.7071067811865475)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(BoW_corpus)\n",
    "words = \"akshay cricket\".lower().split()\n",
    "print(tfidf)\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
